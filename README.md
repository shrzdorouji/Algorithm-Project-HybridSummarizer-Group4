# ğŸš€ Hybrid Text Summarization System
### TextRank + Pegasus (LLM)
**Algorithm Design Course Project â€“ Phase 1 & Phase 2**

---

## ğŸ“Œ Overview

This project implements a **Hybrid Text Summarization System** that integrates:

- **Extractive Summarization (TextRank)** â€“ Graph-based ranking
- **Abstractive Summarization (Pegasus LLM)** â€“ Transformer-based generation

The system combines deterministic ranking with neural generation to produce summaries that are:

- Factually grounded  
- Linguistically coherent  
- Structurally optimized  
- Redundancy-aware  

---

## âœ¨ Key Features

- Dual-Engine Architecture (Graph Theory + Deep Learning)
- Optimized TextRank with Sparse TF-IDF + Min-Heap (O(N log K))
- Local Pegasus Integration (Offline capable)
- Weighted Hybrid Merge Strategy
- Redundancy Filtering Mechanism
- CI/CD Pipeline (GitHub Actions + pytest + flake8)
- Interactive Web UI (Streamlit)

---

## ğŸ—ï¸ System Architecture

```mermaid
flowchart TD
    A[Input Text] --> B[Extractive Layer<br/>TextRank]
    A --> C[Abstractive Layer<br/>Pegasus LLM]
    B --> D[Hybrid Merge Layer]
    C --> D
    D --> E[Final Summary]
```

---

## âš™ï¸ TextRank Module (Extractive Layer)

### Preprocessing
- Sentence segmentation
- Tokenization (NLTK)
- Stopword removal
- Porter Stemming

### Vectorization
- Sparse TF-IDF matrix
- Memory-efficient representation

### Graph Construction
- Cosine similarity matrix
- Configurable similarity threshold (Î¸)
- Damping factor (d = 0.85)
- Convergence tolerance (1e-4)

### Optimization Strategy
- Sparse similarity graph
- Min-Heap for Top-K selection â†’ O(N log K)
- Reduced memory footprint

---

## ğŸ§  LLM Module (Abstractive Layer)

- Model: `PegasusForConditionalGeneration`
- Dynamic summary length adjustment
- Controlled decoding:
  - `top_p`
  - `top_k`
  - `temperature`
- Hallucination mitigation via constrained sampling
- Fully offline compatible (local fine-tuned model)

---

## ğŸ”— Hybrid Merge Strategy (Phase 2 Core Innovation)

Final scoring formula:

\[
Score_{final} = (\alpha \times Score_{TR}) + (\beta \times Score_{LLM})
\]

### Includes:

- Weighted ranking fusion
- Semantic redundancy filtering (SequenceMatcher threshold = 0.6)
- Candidate re-scoring
- Logical reordering by original sentence index
- Balanced precisionâ€“fluency tradeoff

---

## â±ï¸ Complexity Analysis

| Component | Complexity |
|------------|------------|
| Sentence Vectorization | O(N Ã— V) |
| Graph Construction | O(NÂ² Â· V_avg + N log K) |
| PageRank Convergence | O(I Ã— E) |
| Merge Logic | O(MÂ²), where M â‰ª N |

---

## ğŸ§ª Testing & CI/CD

### Unit Testing
- Framework: `pytest`
- Graph correctness validation
- Weight formula verification
- Redundancy filter tests
- LLM mocked during tests for lightweight execution

### Code Quality
- `flake8` (PEP8 compliance)
- Modular architecture validation

### GitHub Actions
Every push to `main` triggers:

- Virtual environment build
- Dependency installation
- Unit test execution
- Style validation

---

## ğŸ“‚ Project Structure

```
Algorithm-Project-HybridSummarizer-Group4/
â”‚
â”œâ”€â”€ .github/workflows/
â”‚   â””â”€â”€ ci-pipeline.yml
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ textrank/
â”‚   â”‚   â”œâ”€â”€ textrank.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â”‚
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â””â”€â”€ llm_integration.py
â”‚   â”‚
â”‚   â””â”€â”€ merge/
â”‚       â””â”€â”€ merge_strategy.py
â”‚
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ğŸ› ï¸ Installation

### 1ï¸âƒ£ Clone Repository

```bash
git clone https://github.com/YourUsername/Project-Name.git
cd Project-Name
```

### 2ï¸âƒ£ Create Virtual Environment (Recommended)

```bash
python -m venv venv
source venv/bin/activate      # Linux / Mac
venv\Scripts\activate         # Windows
```

### 3ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

---

## â–¶ï¸ Run Web Interface

```bash
streamlit run app.py
```

Then open:

```
http://localhost:8501
```

---

## ğŸ“Š Example Workflow

1. Paste input text  
2. Select summary length  
3. System generates:
   - Extractive summary
   - Abstractive summary
   - Hybrid optimized summary  

---

## ğŸ§  Edge Cases Evaluated

- Technical documentation
- Highly redundant paragraphs
- Short input snippets
- Repeated sentence clusters
- Academic structured texts

---

## ğŸ“ˆ Future Improvements

- SBERT similarity integration
- ROUGE & BLEU evaluation metrics
- Multi-document summarization
- Reinforcement tuning of Î± / Î²
- Attention-based redundancy detection
- Performance benchmarking dashboard

---

## ğŸ“ Academic Context

Course: **Algorithm Design**  

Phase 1:
- Optimized TextRank implementation

Phase 2:
- Hybrid fusion logic
- Weight tuning
- Redundancy filtering
- Performance optimization

---

## ğŸ‘¥ Authors

Group 4  

---

## ğŸ“„ License

For academic and educational use only.
